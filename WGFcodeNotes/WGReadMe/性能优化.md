## 性能优化
#### 面试题
1. 你在项目中是怎么优化内存的?
2. 优化你从那几方面着手
3. 列表卡顿的原因有哪些? 你平时是怎么优化的
4. 遇到tabView卡顿吗? 会造成卡顿的原因大致有哪些?

### 1. CPU和GPU
#### 在屏幕成像的过程中,CPU和GPU起着至关重要的作用
* CPU(中央处理器): 对象的创建和销毁、对象属性的调整、布局计算、文本的计算和排版、图片的格式转换和解码、图像的绘制
* GPU(图形处理器): 纹理的渲染

              计算         渲染          读取               显示
        CPU---------GPU---------帧缓存---------视频控制器---------屏幕
* 在iOS中是双缓存机制,有前帧缓存、后帧缓存
#### 1.1 iOS屏幕图像显示原理
#### 1.1.1 显示器屏幕刷新过程
#### 显示器的电子枪是从上到下进行逐行扫描的，扫描完成后显示器就呈现一帧画面，随后电子枪回到初始位置继续下一次扫描。为了把显示器的显示过程和系统的视频控制器进行同步，显示器（或者其他硬件）会用硬件时钟产生一系列的定时信号。显示器通常以“固定频率“进行刷新，这个刷新率就是VSync信号产生的频率。iOS设备的屏幕刷新频率是每秒60帧，平均每16.67ms发出一个VSync。

    HSync：
    当电子枪换到新的一行,准备进行扫描时,显示器会发出一个水平同步信号,简称HSync(horizonal synchronization)
    VSync：
    当一帧画面绘制完成后,电子枪回复到原位,准备画下一帧前,显示器会发出一个垂直同步信号,简称VSync(vertical synchronization)
#### 1.1.2 CPU，GPU以及显示器的协作方式
#### CPU 计算好显示内容提交到 GPU，GPU 渲染完成后将渲染结果放入帧缓冲区，视频控制器收到VSync信号后逐行读取帧缓冲区的数据，再经过一定的数模转换传递给显示器显示。
    屏幕刷新频率：Refresh Rate或Scanning Frequency，单位hz，是指设备刷新屏幕的频率。
    帧率：Frame Rate，单位 fps，是指 GPU 生成帧的速率。
#### 单缓存的问题：GPU 向缓存区中写入数据，视频控制器从缓存区中取图像数据后显示，理想的情况是帧率和屏幕刷新频率相等，每绘制一帧，屏幕就显示一帧。而实际情况是，如果没有同步机制，当帧率大于屏幕刷新频率时，视屏控制器刚逐行读取完第2帧的上半部分时，GPU 已经完成第3帧的渲染并提交到缓存区中，视屏控制器会继续读取第三帧的下半部，这样会造成画面撕裂。为了解决单缓存的效率问题以及画面撕裂问题，一般会引入双缓存区和VSync

#### 1.1.3 iOS屏幕刷新机制
#### 为了解决单缓存区的问题，iOS设备在这个过程中采取了双缓存区+VSync(垂直同步信号)机制
1. GPU 会预先渲染好一帧放入一个缓存区内(前帧缓存);
2. 在显示器发出VSync后,视频控制器的指针会指向前帧缓存区并开始读取,GPU开始渲染下一帧,并将渲染结果放入另一个缓存区(后帧缓存);
3. 在显示器发出新的VSync后,视频控制器的指针会指向后帧缓存区并开始读取，GPU开始渲染下一帧，并将渲染结果放入前帧缓存区。

#### 双缓存和VSync造成的问题
#### 每一帧画面先经过CPU计算，再经过GPU渲染，然后将结果存放在帧缓存区供视频控制器读取，由于垂直同步的机制，如果在一个Vsync时间内，CPU或GPU没有完成内容提交，则那一帧就会被废弃，而此时显示器会保留之前的内容不变，也就造成界面卡顿

#### 1.2卡顿产生的原因
#### 显示内容到屏幕上的过程是: 先通过CPU,然后CPU将计算的结果交给GPU处理,GPU处理完成后等待垂直同步信号(VSync),当垂直同步信号(VSync)到来时,将内容显示到屏幕上
#### 产生卡顿原因: CPU和GPU花费的时间太长,导致垂直同步信号(VSync)来的时候,计算和渲染操作还没有完成,这样就导致掉帧了,所以产生了卡顿

#### 1.2.1 卡顿解决的主要思路
* 尽可能减少CPU、GPU资源消耗
* 按照60FPS(每秒刷新60帧)的刷帧率,每隔16ms(1000毫秒%60)就会有一次垂直同步信号(VSync)

### 2. 卡顿优化
#### 2.1 CPU优化
1. 尽量用轻量级的对象(如用不到事件处理的地方,可以考虑使用CALayer取代UIView；能用基本数据类型，就别用NSNumber类型。)
2. 不要频繁的调整UIView的相关属性(如frame、bounds、transform等属性)尽量减少不必要的修改
3. 尽量提前计算好布局,在有需要时一次性调整对应的属性,不要多次修改属性
4. Autolayout会比直接设置frame消耗更多的CPU资源(如果对性能要求特别高,可以不用Autolayout)
5. 图片的size最好刚好和UIImageView的size保持一致(若不一致,CPU需要对图片进行伸缩处理)
6. 控制一下线程的最大并发数量
7. 尽量把耗时的操作放到子线程
8. 文本处理(尺寸计算、绘制)
9. 图片处理(解码、绘制)

        //文字计算
        [@"sdf" boundingRectWithSize:CGSizeMake(100, MAXFLOAT) options:NSStringDrawingUsesLineFragmentOrigin 
        attributes:nil context:nil];
        
        //文字绘制
        [@"test" drawWithRect:CGRectMake(0, 0, 100, 100) options:NSStringDrawingUsesLineFragmentOrigin 
        attributes:nil context:nil];
        //图片处理
        UIImageView *imgView = [[UIImageView alloc]init];
        通过这种方式加载图片,其实是不会直接显示到屏幕上的,加载的其实是经过压缩后的二进制数据
        如果要渲染到屏幕上,还需再经过解码,解码成屏幕需要的格式,而解码是放在主线程的,所以可能会产生卡顿
        可以把解码放在子线程,具体如何解码可以参考网上好多第三方的库中找到
        imgView.image = [UIImage imageNamed:@"test"];
        [self.view addSubview:imgView];
#### 2.2 GPU优化
1. 尽量减少视图数量和层次
2. 尽量避免短时间内大量图片的显示,尽可能将多张图片合成一张进行显示
3. GPU能处理的最大纹理尺寸是4096*4096,一旦超过这个尺寸,就会占用GPU资源进行处理,所以纹理尽量不要超过这个尺寸
4. 减少透明的视图(alpha < 1),不透明的就设置opaque为YES
5. 尽量避免出现离屏渲染

#### 2.3 离屏渲染
#### 在OpenGL中,GPU有两种渲染方式
1. On-Screen Rendering: 当前屏幕渲染,在当前用于显示的屏幕缓冲区进行渲染操作
2. Off-Screen Rendering: 离屏渲染,在当前屏幕缓冲区以外新开辟一个缓冲区进行渲染操作

#### 离屏渲染消耗性能的原因? 
* 需要创建新的缓冲区
* 离屏渲染的整个过程,需要多次切换上下文环境,先是从当前屏幕(On-Screen)切换到离屏(Off-Screen);等到离屏渲染结束后,将离屏缓冲区的渲染结果显示到屏幕上,又需要将上下文环境从离屏切换到当前屏幕
#### 导致离屏渲染的操作有哪些?
1. 光栅栏(layer.shouldRasterize = YES)
2. 遮罩(layer.mask)
3. 圆角(同时设置layer.maskToBounds=YES,layer.cornerRadius大于0,才会触发离屏渲染),可以通过CoreGraphics绘制裁剪成圆角或者让美工提供圆角图片
4. 阴影(layer.shadowXXX)(如果设置了layer.shadowPath就不会产生离屏渲染)

### 3. 卡顿检测
#### 平时所说的“卡顿”主要是因为在主线程执行了比较耗时的操作,想要检测卡顿,可以通过添加Observer到主线程的Runloop中,通过监听RunLoop状态切换的耗时,来达到检测卡顿的目的.检测卡顿可以借鉴一下一个不错的第三方来详细的查看一下(https://github.com/UIControl/LXDAppFluecyMonitor)

### 4. 耗电的主要来源
1. CPU处理(Processing)
2. 网络(Networking)
3. 定位(Location)
4. 图像(Graphics)

#### 4.1 耗电优化
1. 尽可能降低CPU、GPU功耗(上面已经提过CPU、GPU的优化)
2. 少用定时器
3. 优化I/O操作(文件的读写):  

        尽量不要频繁写入小数据,最好批量一次性写入; 
        读写大量重要数据时,考虑用dispatch_io,它提供了基于GCD的异步操作文件I/O的API,用dispatch_io系统会优化磁盘访问
        数据量比较大的,建议使用数据库(如SQLite、CoreData)
4. 网络优化

        减少、压缩网络数据(XML体积大、JSON体积小、也有用Protocol buffer前提是服务器也用Protocol buffer)
        如果多次请求的结果是相同的,尽量使用缓存(NSCache)
        使用断点续传,否则网络不稳定时可能多次传输相同的内容
        网络不可用时,不要尝试执行网络请求
        让用户可以取消长时间运行或者速度很慢的网络操作,设置合适的超时时间
        批量传输(如下载视频流时,不要传输很小的数据包,直接下载整个文件或一大块一大块的下载;减少发送网络请求的数量)
5. 定位优化

        如果只是需要快速确定用户位置,最好用系统库CoreLocation中CLLocationManager的requestLocation方法,
        定位完成后,会自动让定位硬件断电
        
        如果不是导航应用,尽量不要实时更新位置,定位完毕就关闭定位服务
        尽量降低定位精度,比如尽量不要使用精度最高的KCLLocationAccuracyBest
        需要后台定位时,尽量设置pausesLocationUpdatesAutomatically为YES(若用户不太可能移动时系统会自动暂停位置更新)
        
### 5. APP启动
#### APP启动可以分为两种, APP启动时间的优化,主要针对冷启动进行优化
1. 冷启动: 从零开始启动APP
2. 热启动: APP已经在内存中,在后台存活着,再次点击图标启动APP

#### 通过添加环境变量可以打印出APP的启动时间分析(Edit scheme -> Run -> Arguments -> Environment Variables)
        DYLD_PRINT_STATISTICS设置为1
        若需要更详细的信息,就可以将DYLD_PRINT_STATISTICS_DETAILS设置为1
        
        //设置DYLD_PRINT_STATISTICS设置为1后控制台打印信息(一般在400毫秒比较正常)
        Total pre-main time: 215.43 milliseconds (100.0%)
              dylib loading time:  47.51 milliseconds (22.0%)
             rebase/binding time: 126687488.9 seconds (402107044.3%)
                 ObjC setup time:  22.38 milliseconds (10.3%)
                initializer time: 168.63 milliseconds (78.2%)
                slowest intializers :
                  libSystem.B.dylib :  14.57 milliseconds (6.7%)
        libBacktraceRecording.dylib :   7.52 milliseconds (3.4%)
        libMainThreadChecker.dylib : 136.86 milliseconds (63.5%)
#### 5.1 APP的冷启动可以概括为3个阶段
1. dyld: 加载动态库、可执行文件的阶段
2. runtime: 初始化我们OC结构(类、分类等)
3. main: main函数

#### 5.1.1 dyld
#### dyld(dynamic link editor),Apple的动态链接器,可以用来装载Mach-O文件(可执行文件、动态库等), 
#### Xcode中当我们运行项目后,项目会编译在Products文件夹下的XXX.app,点击XXX.app显示包内容,在里面会有黑色图标的文件XXX,这个文件XXX就是我们项目的可执行文件,这个可执行文件格式就是Mach-O格式文件, 包含了我们项目的所有代码, 但是我们的代码可能会依赖一些动态库,比如UIKit、Foundation等,而这些动态库是不会存在于可执行文件的

#### dyld除了加载我们的可执行文件,将我们的代码各种东西装载到内存中外,还会去检查我们的Mach-O文件还依赖于哪些动态库,又会去加载别的动态库,但是别的动态库又会依赖其他动态库,dyld就依次递归查找依赖动态库并进行加载这些动态库

#### 5.1.2 启动APP时,dyld做的事情
1. 装载APP的可执行文件,同时会递归加载所有依赖的动态库
2. 当dyld把可执行文件、动态库都装载完毕后,会通知Runtime进行下一步的处理


#### 5.2 Runtime, 启动APP时,Runtime做的事情
1. 调用map_images进行可执行文件内容的解析和处理
2. 在load_images中调用call_load_methods,调用所有类Class和分类Category的+load方法
3. 进行各种Objc结构的初始化(注册Objc类、初始化类对象等等)
4. 调用C++静态初始化器和__attribute__((constructor))修饰的函数
#### 到此为止,可执行文件和动态库中所有的符号(Class、Protocol、Selector、IMP、...)都已经按格式成功加载到内存中,被Runtime所管理,然后进入下一步main函数阶段

#### 5.3 总结
1. APP的启动由dyld主导,将可执行文件加载到内存中,顺便加载所有依赖的动态库
2. 并由Runtime负责加载成Objc定义的结构
3. 所有初始化工作结束后,dyld就会调用main函数
4. 接下来就是UIApplicationMain函数,AppDelete的didFinishLaunchingWithOptions方法

#### 6 APP启动优化
#### 按照不同的阶段进行不同的优化
* dyld阶段

        1. 减少动态库、合并一些动态库(定期清理不必要的动态库)
        2. 减少Objc类、分类的数量、减少Selector数量(定期清理不必要的类、分类)
        3. 减少C++虚函数数量
        4. Swift尽量使用struct

* Runtime阶段

        用+initialize方法和dispatch_once取代所有的__attribute__((constructor))、C++静态构造器、Objc的+load方法

* main

        在不影响用户体验的前提下,尽可能将一些操作延迟,不要全部都放在didFinishLaunchingWithOptions方法中
        按需加载
        
#### 7. 安装包瘦身
#### 安装包(ipa)主要由可执行文件、资源组成,瘦身主要从这两方面入手
* 资源(图片、音频、视频等)瘦身

        1. 采取无损压缩
        2. 去除没有用到的资源(https://github.com/tinymind/LSUnusedResources)
* 可执行文件瘦身

        1.编译器优化
            Strip Linked Product、Make Strings Read-Only、Symbols Hidden by Default设置为YES
            去掉异常支持(Enable C++ Exceptions、Enable Objective-C Exceptions设置为NO)
            Other C Flags 添加 -fno-exceptions
        2.利用AppCode(https://www.jetbrains.com/objc/)检测未使用的代码(菜单->Code->Inspect Code)(免费时间可用)
        3.编写LLVM插件检测出重复代码、未被调用的代码(难度比较大,仅作为一种瘦身方法了解即可)
        4.生成LinkMap文件,可以查看可执行文件的具体组成(X.txt文件)
        Build Settings -> Write Link Map File设置为YES
        Path to Link Map File 修改$(TARGET_TEMP_DIR)路径为桌面下的某个路径,然后运行项目,就会在指定路径下生成文件X.txt
        当文件X.txt比较大时,可借助第三方工具解析LinkMap文件,来详细查看各个类占用的内存大小(KB单位)
        https://github.com/huanxsd/LinkMap
        
#### 8 性能调优之像素对齐-Color Misaligned Images优化
#### iOS项目中的尺寸是以点(point)为单位,@1x、@2x、@3x代表分别表示一个点对应1个像素、对应2个像素、对应3个像素。而Color Misaligned Images主要就是针对像素不对齐而导致性能问题进行优化处理的
#### 发现项目中存在Misaligned Images问题的方式有两种
1. 模拟器调试时：打开模拟器的Debug - Color Misaligned Images菜单选项
2. Instrument性能检测时，选中Core Animation模板，在Display Settings中勾选Color Misaligned Images选项。可针对模拟器和真机，可查看真机上所有应用的像素混合情况
#### 打开开关后，会看到部分视图出现黄色或洋红色图层标记，代表其像素不对齐
    不对齐: 视图或者图片的点数(point)，不能换算成整数倍的像素值(pixel),导致显示视图时需要对没对齐的边缘进行额外混合计算，
    影响性能洋红色: UIView的frame像素不对齐，即不能换算成整数像素值
    
    黄色: UIImageView的图片像素大小与其frame.size不对齐，图片发生了缩放造成
    
    点(point): 逻辑坐标的基本单位，日常布局中常用的，比如某个视图的宽度为20高度为40，点是虚拟单位，并非实际存在，
    还需GPU计算点对应的像素
    
    像素pixel: 屏幕上最小的色块单元，如iPhone6s的屏幕像素是750x1334像素，对应的点是375*667pt,点和像素的对应关系是1:2,
    所以iPhone6s上需要使用@2x的图片
    
#### 一般UI设计师给的设计图都是像素(px)为单位或者点(pt)为单位，本案例以设计图以像素(px)为单位，如果设计图中图标@2x尺寸为40*40像素，那么实际项目中如果我们在iPhone6s下设置布局时，应该设置它的size为20*20(原因是iPhone6s用的是@2x的图标，即iPhone6s屏幕上的一个点代表2个像素)，否则会出现像素不对齐的问题，所以以后让设计出图出图(像素px为单位时)，尽量@2x的图是项目布局设置尺寸的2倍，对应的@3x是项目布局尺寸的3倍，这样就不会出现像素不对齐而导致性能问题了

#### 洋红色: UIView的frame像素不对齐，即不能换算成整数像素值问题的解决；解决方法就是根据屏幕倍数对点进行向上取整
    0.5个点在@3x(即一个点代表3个像素)的设备上不能转化为整数的像素，
    label.frame = CGRectMake(0.5, 10, 20.5, 30);
    
    
    OC中无法对CGFloat、CGSie、CGRect进行分类添加方法，所以该方法写在全局工具类中
    /// 基于屏幕倍数，进行像素取整
    +(CGFloat)scalePixelInteger:(CGFloat)fl {
        //通过UIScreen.main.scale来获取像素与点的对应关系。
        CGFloat newScale = UIScreen.mainScreen.scale;
        //fl * newScale 点*屏幕倍数 = 像素,然后对像素进行向上取整
        //ceil: 如果参数是小数，则求大于本身的最小整数.
        return ceil(fl * newScale) / newScale;
    }
    
    CGfloat x = [WGUtil scalePixelInteger:0.5];
    CGfloat w = [WGUtil scalePixelInteger:20.5];
    label.frame = CGRectMake(x, 10, w, 30);
    这样就不会再出现洋红色了
    

#### 黄色: UIImageView的图片像素大小与其frame.size不对齐，图片发生了缩放造成；解决方法就是根据图片的像素大小，然后调整布局中的位置；或者让设计师重新出图



### iOS渲染原理
    1.我们在屏幕上绘制图像需要的原始数据叫【位图(Bitmap)】,位图是一种数据结构，一个位图由n*m个像素组成
     每个像素的颜色信息由RGB组合或灰度值表示
     
    2.位图一般存储的是物理像素(物理分辨率)，而应用层一般用的是逻辑像素(逻辑分辨率)
        物理分辨率以pixel(px)为单位；逻辑分辨率以point(pt)为单位;
        iOS 1X倍屏: 1pt = 1个物理像素
        iOS 2X倍屏: 1pt = 2个物理像素
        iOS 3X倍屏: 1pt = 3个物理像素
        
     3.ios开发界面设置长度是以pt(点)为单位的，比如iPhone7plus屏幕尺寸414pt*736pt，所以pt是iOS的开发单位,
     而美工给我们的都是以像素(px)为单位的的
     
     4.屏幕上绘制图像显示的原始数据叫【位图】:电子抢从上到下逐行扫描，扫描一行发出一个Hsync水平同步信号，扫描完成后就显示一帧画面，
     然后电子抢回到初始位置准备进行下一次扫描，在下一次扫描前会发出一个Vsync垂直同步信号，显示器通常以固定的频率进行刷新，这个刷新率就是垂直同步信号
     产生的频率
     
     4.【位图】数据是由CPU、GPU协同工作得到的；
        CPU将计算好显示内容提交给GPU
        GPU渲染完成后将渲染结果存入帧缓冲区
        视频控制器会读取帧缓冲区器的信息传递给显示器进行显示
        
     5.CPU和GPU区别
        CPU:中央处理器，适合处理单一复杂逻辑；cache占用了大量的空间，而且还有特别复杂的控制逻辑，相比之下，计算能力只是CPU 很小的一部分
        GPU:图像处理器，适合高并发简单逻辑；图像渲染涉及到的矩阵运算比较多，矩阵相关的计算可以被拆分成并行的简单的运算，所以渲染处理适合GPU做
        GPU 的工作计算量大，但技术含量不高，需要简单重复很多次；CPU 就像老教授，积分微分都会算，适合处理单一复杂逻辑运算
        
    6.iOS渲染原理
    (1)ios图形渲染有三个核心的库: Core Graphics、Core Animation、Core Image,三个框架主要用来绘制可视化内容,他们都是通过 OpenGL 来
        调用 GPU 进行实际的渲染，然后生成最终位图数据存储到帧缓冲区，视频控制器再将帧缓冲区的数据显示物理屏幕上。
    (2)UIKit是 iOS 开发者最常用的框架,通过设置 UIKit 组件的布局以及相关属性来绘制界面。但是 UIKit 并不具备在屏幕成像的能力，
       这个框架主要负责对用户操作事件的响应（UIView 继承自 UIResponder），事件经过响应链传递。
    (3)Core Animation  主要负责组合屏幕上不同的可视内容，这些可视内容可被分解成独立的图层也就是我们日常开发过程中常接触的 CALayer，
       这些图层被存储在图层树中。CALayer 主要负责页面渲染，它是用户能在屏幕上看见的一切的基础;
    (4)Core Graphics 主要用于运行时绘制图像。开发者可以使用此框架来处理基于路径的绘图，转换，颜色管理，离屏渲染，图案，渐变和阴影等等。
    (5)Core Image  与  Core Graphics 正好相反，Core Graphics  是在运行时创建图像，而  Core Image  则是在运行前创建图像。
    (6)OpenGL ES 和 Metal 都是第三方标准，基于这些标准具体的内部实现是由对应的 GPU 厂商开发的。Metal 是苹果的一套第三方标准，
       由苹果实现。很多开发者都没有直接使用过  Metal，但却通过 Core Animation、Core Image 这些核心的系统框架在间接的使用 metal
       
    7.CoreAnimation 与 UIKit 框架的关系
    (1)Core Animation 是 iOS 和 OS X 上图形渲染和动画的基础框架，主要用来给视图和应用程序的其他可视元素设置动画。Core Animation
       的实现逻辑是将大部分实际绘图的工作交给 GPU 加速渲染，这样不会给 CPU 带来负担，还能实现流畅的动画。CoreAnimation 的核心类是
       CALayer，UIKit 框架的核心类是 UIView
    (2)UIView 和 CALayer 是一一对应的关系，每一个 UIView 都有一个 CALayer 与之对应，UIView负责布局、交互响应，CALayer负责页面渲染
          CALayer 是 UIView 的属性之一，负责渲染和动画，提供可视内容的呈现;UIView 提供了对 CALayer 功能的封装，负责了交互事件的处理
          
    8.为什么要分离出 CALayer 和 UIView？
       iOS 平台和 MacOS 平台上用户的交互方式有着本质的不同，但是渲染逻辑是通用的，在 iOS 系统中我们使用的是 UIKit 和 UIView，而在 MacOS
       系统中我们使用的是 AppKit 和 NSView，所以在这种情况下将展示部分的逻辑分离出来跨平台复用
       
    9.Core Animation 流水线
      Core Animation 整个流水线中 app 本身并不负责渲染，渲染则是由一个独立的进程负责，即 Render Server 进程
     【应用阶段】:
               1.视图的创建
               2.布局计算
               3.对图层进行打包，在下一次 RunLoop 时将其发送至  Render Server
               4.app 处理用户的点击操作，在这个过程中 app 可能需要更新视图树，如果视图树发生更新，图层树也会被更新
               5.app 通过 CPU 完成对显示内容的计算
     【Render Server & GPU】:
               1.主要执行 metal、Core Graphics 等相关程序，并调用 GPU 在物理层上完成对图像的渲染
               2.GPU 将渲染后的位图数据存储到 Frame Buffer（帧缓冲区）
     【Display】：视频控制器将帧缓冲区的位图数据一帧一帧的显示在物理屏幕上
     
     上面的流程步骤执行完成的时间超过了16.67 ms，为了满足对屏幕的 60 FPS 刷新率的支持，需要通过流水线的方式将这些步骤并行执行
     每一个阶段都在源源不断的给下一个阶段输送产物。这时候就可以满足 16.67 毫秒产生一帧数据的要求了
     
     10.iOS离屏渲染
     正常的渲染流程：CPU 和 GPU 协作，不停地将内容渲染完成后得到的位图数据放入 Framebuffer （帧缓冲区）中，视频控制器则不断地
                  从 Framebuffer 中获取内容，显示实时的内容
     离屏渲染的流程：需要先额外创建离屏渲染缓冲区 ，将提前渲染好的内容放入其中，等到合适的时机再将 Offscreen Buffer 中的内容
                  进一步叠加、渲染，完成后将结果再写入 Framebuffer 中
                  
     11.为什么将数据存放在离屏渲染缓冲区？
       （1）一些特殊效果需要使用额外的 Offscreen Buffer 来保存渲染的中间状态（被动）
       （2）出于效率目的，可以将内容提前渲染保存在 Offscreen Buffer 中，达到复用的目的。（主动）
       
     12.常见的触发被动离屏渲染的场景
        【透明】、【阴影】、【圆角】
        
     13.触发离屏渲染的原因？
        (1)画家算法的整体思想是按层绘制，首先绘制距离较远的场景，然后用绘制距离较近的场景覆盖较远的部分。这里的层在 iOS 的渲染技术栈中就
         可以被对应到 layer。
        (2)通常对于每一层 layer，Render Server 会遵循“画家算法”，按次序输出到 frame buffer，后一层覆盖前一层，就能得到最终的
        显示结果，对于这个 layer 树则是以深度优先的算法将 layer 输出到 frame buffer。
        (3)作为“画家”的 GPU 虽然可以一层一层往画布上进行输出，但是却没有办法在某一层渲染完成之后，再回过头来改变其中的某个部分。因为在这一层之前的
        若干层 layer 像素数据，已经在渲染中被合成在一起了,所以需要在离屏缓冲区中把子 layer 依次画好，然后把四个角裁剪好之后再和之前的图层进行混合
        
     14.如何防止非必要离屏渲染？
        (1)对于一些圆角可以创建四个背景颜色弧形的 layer 盖住四个角，从视觉上制造圆角的效果
        (2)对于 view 的圆形边框，如果没有 backgroundColor，可以放心使用 cornerRadius 来做
        (3)对于所有的阴影，使用 shadowPath 来规避离屏渲染
        (4)对于特殊形状的 view，使用 layer mask 并打开 shouldRasterize 来对渲染结果进行缓存































